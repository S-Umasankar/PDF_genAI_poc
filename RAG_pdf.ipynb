{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx2ijDV8bljHHob48IqCD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Umasankar/PDF_genAI_poc/blob/develop/RAG_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f2xgQGsFsQp"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! pip install torch\n",
        "! pip install pdfplumber\n",
        "! pip install sentence_transformers\n",
        "! pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iBUy_5YOn2N",
        "outputId": "4da052ce-c889-4029-96ca-e99c835513ab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/'NLP project - POC'/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wusz1m_ROuMu",
        "outputId": "439fefb6-5df9-443b-f099-5d058a9ad5ba"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP project - POC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import pdfplumber\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
      ],
      "metadata": {
        "id": "X6tzaUhLQcki"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        full_text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            full_text += page.extract_text()\n",
        "    return full_text.split(\"\\n\\n\")  # Split into sections or paragraphs"
      ],
      "metadata": {
        "id": "lEc2qkxVOwSR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):  # Check if text is a string\n",
        "        return \"\"  # Return an empty string for None or non-string objects\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
        "    text = re.sub(r'\\n', '', text)  # Remove extra \\n\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbokDXFkPAb4",
        "outputId": "d25ec3c2-7a07-4e0f-9a3e-bbb7547d4bb6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def embed_text(text):\n",
        "  return sentence_model.encode([text])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INd66R_iPDM9",
        "outputId": "40595023-9812-4f93-de52-3d1fc82d384d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimension = 4000 # Dimension of the embeddings\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "def index_embeddings(embeddings):\n",
        "  faiss_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "  faiss_index.add(embeddings)\n",
        "  return faiss_index\n"
      ],
      "metadata": {
        "id": "UK0lWXDTPBG1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_embeddings(query, index, k=2):\n",
        "  query_embedding = embed_text(query)\n",
        "  distances, indices = index.search(np.array([query_embedding]), k)\n",
        "  return indices[0]"
      ],
      "metadata": {
        "id": "f0rxrxYlPX6B"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_files = [path for path in os.listdir() if path.endswith('.pdf')]\n",
        "texts = [extract_text_from_pdf(file) for file in pdf_files]\n",
        "embeddings = np.array([embed_text(preprocess_text(text)) for text in texts])\n",
        "index = index_embeddings(embeddings)"
      ],
      "metadata": {
        "id": "9Ghdbu01P-5U"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "def generate_response(context):\n",
        "  # Encode the input query using the tokenizer\n",
        "  inputs = tokenizer.encode(context, return_tensors='pt')\n",
        "\n",
        "  # Generate a response\n",
        "  outputs = model.generate(inputs, max_length=25, num_return_sequences=1)\n",
        "\n",
        "  # Decode the generated response\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return response"
      ],
      "metadata": {
        "id": "lATfjBtdPckw"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(query):\n",
        "  response = generate_response(query)\n",
        "  return response\n",
        "\n",
        "# Example usage\n",
        "query = 'What is astrology?'\n",
        "response = chatbot(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laRuPrEdPkdM",
        "outputId": "6d2f17ab-f2da-4a6f-fc88-4fca82461436"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is astrology?\n",
            "\n",
            "Astrology is a science that uses the power of the sun to tell us what is happening\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is mystic science?'\n",
        "response = chatbot(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZq9SCmKRMkI",
        "outputId": "92e069e4-1e1d-4bfc-ca0d-704a96cf613a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is mystic science?\n",
            "\n",
            "The term mystic science is used to describe the study of the nature of the universe. It\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is karma?'\n",
        "response = chatbot(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-Whs6Hr6-wb",
        "outputId": "75f1f1cd-3255-4a71-cbc5-e51e5cca6ac7"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is karma?\n",
            "\n",
            "Karma is the ability to change the world. It is the ability to change the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvJ2YEsP_Suq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}